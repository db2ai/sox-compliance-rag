**SOX Compliance RAG Pipeline**
---------------------------------------------------------------------------------------------------------------------

This is a personal learning project where Iâ€™m combining my background as an Oracle DBA (16+ years) with my current journey into AI and LLMs.
The goal: build a Retrieval-Augmented Generation (RAG) pipeline that not only answers questions from documents, but also does so in a way that feels closer to enterprise compliance standards (like SOX) â€” with audit trails, tamper-evidence, and reproducibility.

**Why Iâ€™m Building This**
---------------------------------------------------------------------------------------------------------------------

Most RAG demos show you how to stuff documents into a vector store and ask questions. Thatâ€™s fine for experiments, but in the real world (especially in regulated industries) we also need to think about:

1. Audit logs: Who asked what, and what evidence was used to answer?
2. Tamper-evidence: How do I know the documents werenâ€™t changed after ingestion?
3. Reproducibility: Can I re-create the exact same answer tomorrow, with proof?
4. Hybrid search: Sometimes keyword (lexical) search is more precise than semantic embeddings â€” so why not use both?

This project is my way of showing how a DBA mindset (data integrity, indexing, compliance) can add value to modern AI systems.

**What This Project Does**
---------------------------------------------------------------------------------------------------------------------

1. Document ingestion â†’ PDFs, text files, or database extracts
2. Hashing & manifests â†’ SHA256 checksums so source files canâ€™t be silently changed
3. Chunking â†’ split text into 500â€“1000 token windows with overlap
4. Vector embeddings â†’ using sentence-transformers stored in ChromaDB
5. Lexical search â†’ using SQLite FTS5 (BM25 ranking)
6. Hybrid retrieval â†’ combine semantic + lexical results
7. Re-ranking â†’ improve relevance with a cross-encoder
8. LLM answer generation â†’ OpenAI API (for now, to keep it lightweight)
9. Audit logging â†’ every query + response is logged with model version and retrieved chunks
10. Evidence bundles â†’ package up manifests + indexes so answers can be re-verified later

**Tech Stack**
---------------------------------------------------------------------------------------------------------------------

 LangChain (orchestration), 
 ChromaDB (vector store), 
 SQLite FTS5 (lexical search), 
 SentenceTransformers for embeddings, 
 OpenAI API for answer generation, 
 Flask for a simple web UI (WIP), 
 Python 3.12

**Quickstart**
---------------------------------------------------------------------------------------------------------------------

python main.py

**Project Structure**
---------------------------------------------------------------------------------------------------------------------
.
â”œâ”€â”€ ingest/        # Ingestion and hashing
â”œâ”€â”€ index/         # Chroma + SQLite indexes
â”œâ”€â”€ retriever/     # Hybrid retrieval + reranking
â”œâ”€â”€ audit/         # Logs and evidence bundles
â”œâ”€â”€ server/        # Flask/FastAPI UI (WIP)
â”œâ”€â”€ tests/         # Unit tests
â”œâ”€â”€ main.py        # Entry point
â””â”€â”€ README.md

**Current Status**
---------------------------------------------------------------------------------------------------------------------

âœ… Repo initialized
âœ… Project skeleton in place

â³ Baseline pipeline with Chroma + SQLite hybrid search

â³ Audit logging and evidence bundle export

â³ Simple Flask UI

ğŸ”® Next Steps

Add role-based access filters (RBAC)

Automate nightly re-indexing

Record a demo video (ingest â†’ query â†’ audit log â†’ evidence bundle)

ğŸ“œ License

MIT License â€” free to use, adapt, and share.

